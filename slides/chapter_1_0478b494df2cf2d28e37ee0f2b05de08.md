---
title: Insert title here
key: 0478b494df2cf2d28e37ee0f2b05de08

---
## Dataset Shift

```yaml
type: "TitleSlide"
key: "97d7bf3bf0"
```

`@lower_third`

name: Dr. Chris Anagnostopoulos
title: Honorary Associate Professor, Imperial College London


`@script`
Welcome back! Sometimes, machine learning models perform less well in production than during development. This can cause much disappointment, and is commonly attributed to overfitting. There is however another possibility: your production data might differ in subtle ways from your training data, so that the patterns your model had picked up are no longer relevant.


---
## What is dataset shift?

```yaml
type: "FullSlide"
key: "f487295fbe"
```

`@part1`
**Temporal data shift**: 
- The presence of the keyword "Microsoft Excel" in a Curriculum Vitae has become less important as a predictor of a good applicant for a data analysis job.
- With the introduction of two-step authentication techniques, multiple password attempts are less frequently involved in cyber attacks.

**Change of domain** or **source**: 

- An OCR (optical character recognition) software might be deployed on wrinkled, faded receipts, whereas it was trained on high quality scanned documents. 
- An app that predicts imminent heart attack was trained only on elderly males.


`@script`
Often, the data generating process evolves over time. For example, if you were building a decision making tool for recruitment of data analysts, skills that used to be relevant in the past might be less so today. Similarly, as cyberdefenders become more sophisticated, so do cybercriminals, reducing the usefulness of past attack signatures. Another possibility is that the data source itself might change from development to production. For example, high quality academic datasets might be used to train an algorithm which is then deployed in a consumer product generating less reliable data.


---
## A real example of dataset shift.

```yaml
type: "TwoRows"
key: "ed43677062"
```

`@part1`
- The `electricity` dataset is popular in the literature on dataset shift. 
- Class: `up` or `down`, 5 features (plus timestamp), 45312 instances. 
- You can find more information [here](https://www.openml.org/d/151). For now, let's import it and sort by date.


`@part2`
```python
import pandas as pd
df = pd.read_csv(
    'https://www.openml.org/data/get_csv/2419/electricity-normalized.arff'
)
df = df.sort_values(by='date').reset_index().drop(['date', 'index'], axis=1)
print(df.head(3))
   day    period  nswprice  nswdemand  vicprice  vicdemand  transfer class
0    2  0.000000  0.056443   0.439155  0.003467   0.422915  0.414912    UP
1    2  0.553191  0.042482   0.499554  0.003467   0.422915  0.414912  DOWN
2    2  0.574468  0.044374   0.491669  0.003467   0.422915  0.414912    UP
```


`@script`
Let's look at an example. We will aim to forecast electricity price movements on the basis of a number of features. The class label here is "UP" or "DOWN". This trick of turning a forecasting problem into a classification problem is worth keeping in mind, as it allows you to use your standard pipeline in a broader set of problems.


---
## A real example of dataset shift.

```yaml
type: "FullCodeSlide"
key: "8db1d9751c"
```

`@part1`
```python
from sklearn import naive_bayes as nb, metrics
training_data = {'old': df.loc[0:20000], 'new': df.loc[20001:40000]}
live_data = df.loc[40001:]
models = {key: nb.GaussianNB().fit(X=val.drop('class', 1), y=val['class'])
          for key, val in training_data.items()}
predictions = {key: val.predict(live_data.drop('class', 1))
               for key, val in models.items()}
accuracies = {key: metrics.accuracy_score(live_data['class'], val)
              for key, val in predictions.items()}
print({key: '{:f}'.format(val) for key, val in accuracies.items()})
{'new': '0.823574', 'old': '0.787987'}
```
Training on more recent data gives better  accuracy than training on older data.


`@script`
To illustrate the effects of dataset shift, we split the data in two batches of 20000 examples each, sorted by date, and hold out the last few thousand examples as our "production" data. Training on the older batch produces lower accuracy against the production data than training on recent data: the data is shifting. The literature attributes this shift to a structural change in the power grid during the period in question. In practice, you might not know for sure whether your dataset has shifted, or why, but remember that it is always possible: the world is a very dynamic place!


---
## Data splitting revisited

```yaml
type: "TwoColumns"
key: "9d95c3b273"
```

`@part1`
Should production data be used as training data, test data, or both? 

Flexible models and/or model selection are more sensitive to shift in the test set. Simple models and light use of the test set (say, for regularisation) means the training set is more important. 

It might be necessary to place more weight on the production examples in the training set (see next exercise).


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/ea4451428be1e0011611606a4f42a8a97706e72f/datasplitting.001.jpeg)


`@script`
Often, labelled production data are hard to get. Some experts recommend using it all as test, rather than training data. This assumes that your models are robust to dataset shift during training, which tends to be true for very flexible models, like deep neural nets or random forests. It is also advisable if your pipeline relies heavily on model selection or ensembles, which is most sensitive to shift in the test set. If, on the other hand, you are fitting simpler models, or making light use of the test set, say, only for regularisation, you might want to spread your production data across both training and test. You can place more weight on production instances to help them stand out against the training set using weighted learning techniques.


---
## The Landscape of Solutions

```yaml
type: "TwoColumns"
key: "9d2128bd6a"
```

`@part1`
There are several different ways to handle dataset shift:
- model and/or data averaging
    - exponential forgetting factors
    - weighted ensemble learning
- pre-training and transfer learning


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/d7acecef3d765a4b738ff4969afff21c2ba23834/surface.png)
![](https://assets.datacamp.com/production/repositories/3450/datasets/32f1c1a1439504fe2148b46fc393d9b819df75e0/transfer.001.jpeg)


`@script`
We have already alluded to data re-weighting, and model selection or ensembles using production data as possible remedies to dataset shift. When training occurs via incremental techniques like gradient descent, an alternative approach is to use the parameter values obtained using the historical set to initialise a few more rounds of gradient descent on the production data. This assumes that the pre-trained model is a local optimum that lies closer to the global optimum than a random initialisation. An alternative technique sometimes referred to as transfer learning is to fix part of the model parameters to the values obtained from the historical set, and train only the remaining ones using production data. For example, we might fix all layers of a neural network but the last one.


---
## You're ready to tackle the exercise on online learning!

```yaml
type: "FinalSlide"
key: "32422b5027"
```

`@script`
You have learnt a lot in the last few minutes. Now it's time to dive into a special kind of dataset shift known as concept drift, in the context of online learning!

