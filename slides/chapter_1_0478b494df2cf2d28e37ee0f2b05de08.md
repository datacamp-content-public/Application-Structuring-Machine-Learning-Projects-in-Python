---
title: Insert title here
key: 0478b494df2cf2d28e37ee0f2b05de08

---
## Dataset Shift and Domain Adaptation

```yaml
type: "TitleSlide"
key: "97d7bf3bf0"
```

`@lower_third`

name: Chris Anagnostopoulos
title: Dr.


`@script`
Welcome back! Sometimes, machine learning models tend to perform less well in production than during development. This can cause much disappointment, and is commonly attributed to overfitting, a topic we covered earlier. There is however another possibility: your production data might differ in subtle ways from your training data, so that the patterns your model correctly picked up are not as relevant. Let's dig deeper into this situation, and how it can be fixed.


---
## What is dataset shift? 

```yaml
type: "FullSlide"
key: "f487295fbe"
```

`@part1`
Sometimes, the relationship between $X$ and $y$ changes over **time**. 
- The presence of the keyword "Microsoft Excel" in a Curriculum Vitae has become less important as a predictor of a good applicant for a data analysis job.
- With the introduction of two-step authentication techniques, multiple password attempts are no longer a serious warning sign of a cyber attack.

In other cases, the shift is not temporal, but rather a **change of domain**: 

- An OCR (optical character recognition) software might be deployed on wrinkled, half-faded receipts, whereas it was trained on high quality scanned documents. 
- An app that predicts imminent heart attack was trained only on elderly males.


`@script`



---
## An example of dataset shift: credit scoring

```yaml
type: "TwoRows"
key: "ed43677062"
```

`@part1`
Let's look at an example from the Kaggle competition "Give me some credit"


`@part2`
```python
s = "Python syntax highlighting"
print s
# show some data
```


`@script`
It probably seems obvious that deploying a model on data that are very different from its training set is a bad idea. But let's review some technical detail to understand precisely what is at play here. We will look at a credit scoring example used in the Kaggle competition "show me some credit". Credit scoring is one of the earliest success stories in supervised learning. The task is to predict the probability that a customer will default on their loan (i.e., fail to pay it back) based on their application data. For example, being chronically unemployed is indicative of a high risk of default -- and so on. This classification used to be made by the gut feeling of an employee of the bank, whereas now it is made by decision trees trained on historical data of loan applications and default outcomes: these are called "scorecards" in the industry.


---
## Why is it a problem?

```yaml
type: "FullCodeSlide"
key: "1e28be7221"
```

`@part1`
```python
s = "Python syntax highlighting"
print s
# show some data
```


`@script`



---
## Different types of shift

```yaml
type: "FullSlide"
key: "3b3dd0d533"
```

`@part1`



`@script`



---
## Data splitting revisited

```yaml
type: "FullSlide"
key: "82daafb3a0"
```

`@part1`



`@script`



---
## The Landscape of Solutions

```yaml
type: "FullSlide"
key: "e914a70c1f"
```

`@part1`
There are several ways to handle dataset shift:
- pre-training and model initialisation
- parameter subspace and transfer learning
- model and/or data averaging
    - exponential forgetting factors / data decay
    - weighted ensemble learning


`@script`



---
## Deep dive in online learning

```yaml
type: "FullSlide"
key: "0be3dddb34"
```

`@part1`



`@script`



---
## Challenge: handwritten digit recognition

```yaml
type: "FinalSlide"
key: "32422b5027"
```

`@script`


