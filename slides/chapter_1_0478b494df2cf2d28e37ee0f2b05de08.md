---
title: Insert title here
key: 0478b494df2cf2d28e37ee0f2b05de08

---
## Dataset Shift and Domain Adaptation

```yaml
type: "TitleSlide"
key: "97d7bf3bf0"
```

`@lower_third`

name: Chris Anagnostopoulos
title: Dr.


`@script`
Welcome back! Sometimes, machine learning models tend to perform less well in production than during development. This can cause much disappointment, and is commonly attributed to overfitting, a topic we covered earlier. There is however another possibility: your production data might differ in subtle ways from your training data, so that the patterns your model correctly picked up are not as relevant. Let's dig deeper into this situation, and how it can be fixed.


---
## What is dataset shift? 

```yaml
type: "FullSlide"
key: "f487295fbe"
```

`@part1`
Sometimes, the relationship between $X$ and $y$ changes over **time**. 
- The presence of the keyword "Microsoft Excel" in a Curriculum Vitae has become less important as a predictor of a good applicant for a data analysis job.
- With the introduction of two-step authentication techniques, multiple password attempts are less frequently involved in cyber attacks.

In other cases, the shift is not temporal, but rather due to a **change of domain**: 

- An OCR (optical character recognition) software might be deployed on wrinkled, faded receipts, whereas it was trained on high quality scanned documents. 
- An app that predicts imminent heart attack was trained only on elderly males.


`@script`



---
## A real example of dataset shift.

```yaml
type: "TwoRows"
key: "ed43677062"
```

`@part1`
- The `electricity` dataset is popular in the literature on dataset shift. 
- Class: `up` or `down`, 5 features (plus timestamp), 45312 instances. 
- You can find more information [here](https://www.openml.org/d/151). For now, let's import it and sort by date. 
- Next, we will fit the same classifier to older and more recent data, and assess its accuracy against the most recent 500 examples.


`@part2`
```python
import pandas as pd
df = pd.read_csv(
    'https://www.openml.org/data/get_csv/2419/electricity-normalized.arff'
)
df = df.sort_values(by='date').reset_index().drop(['date', 'index'], axis=1)
print(df.head(3))
   day    period  nswprice  nswdemand  vicprice  vicdemand  transfer class
0    2  0.000000  0.056443   0.439155  0.003467   0.422915  0.414912    UP
1    2  0.553191  0.042482   0.499554  0.003467   0.422915  0.414912  DOWN
2    2  0.574468  0.044374   0.491669  0.003467   0.422915  0.414912    UP
```


`@script`
It probably seems obvious that deploying a model on data that are very different from its training set is a bad idea. But let's review some technical detail to understand precisely what is at play here. We will look at a credit scoring example used in the Kaggle competition "show me some credit". Credit scoring is one of the earliest success stories in supervised learning. The task is to predict the probability that a customer will default on their loan (i.e., fail to pay it back) based on their application data. For example, being chronically unemployed is indicative of a high risk of default -- and so on. This classification used to be made by the gut feeling of an employee of the bank, whereas now it is made by decision trees trained on historical data of loan applications and default outcomes: these are called "scorecards" in the industry.


---
## Why is it a problem?

```yaml
type: "TwoRowsWideTop"
key: "91ffa0b78b"
```

`@part1`



`@part2`
Check


`@part3`
```python
from sklearn import naive_bayes as nb, metrics
training_data = {'old': df.loc[0:20000], 'new': df.loc[20001:40000]}
live_data = df.loc[40001:]
models = {key: nb.GaussianNB().fit(X=val.drop('class', 1), y=val['class'])
          for key, val in training_data.items()}
predictions = {key: val.predict(live_data.drop('class', 1))
               for key, val in models.items()}
accuracies = {key: metrics.accuracy_score(live_data['class'], val)
              for key, val in predictions.items()}
print({key: '{:f}'.format(val) for key, val in accuracies.items()})
{'new': '0.823574', 'old': '0.787987'}
```


`@script`



---
## Why is it a problem?

```yaml
type: "TwoRowsWideBottom"
key: "878dd774d9"
```

`@part1`
```python
from sklearn import naive_bayes as nb, metrics
training_data = {'old': df.loc[0:20000], 'new': df.loc[20001:40000]}
live_data = df.loc[40001:]
models = {key: nb.GaussianNB().fit(X=val.drop('class', 1), y=val['class'])
          for key, val in training_data.items()}
predictions = {key: val.predict(live_data.drop('class', 1))
               for key, val in models.items()}
accuracies = {key: metrics.accuracy_score(live_data['class'], val)
              for key, val in predictions.items()}
print({key: '{:f}'.format(val) for key, val in accuracies.items()})
{'new': '0.823574', 'old': '0.787987'}
```


`@part2`
When facing dataset shift, you risk fitting the  parameters of your model to obsolete patterns, leading to poor accuracy, as in the example above. However, dataset shift **does not always** hurt your model, as some types of shift might not affect the decision boundary .


`@part3`
![](https://assets.datacamp.com/production/repositories/3450/datasets/5d5fbecc3b774ab94af69ea48ab73a8aa98f14e0/shift_types_hard_cropped.png) 
A toy example of harmless dataset shift.


`@script`



---
## Different types of shift

```yaml
type: "FullSlide"
key: "3b3dd0d533"
```

`@part1`



`@script`



---
## Data splitting revisited

```yaml
type: "FullSlide"
key: "82daafb3a0"
```

`@part1`



`@script`



---
## The Landscape of Solutions

```yaml
type: "FullSlide"
key: "e914a70c1f"
```

`@part1`
There are several ways to handle dataset shift:
- pre-training and model initialisation
- parameter subspace and transfer learning
- model and/or data averaging
    - exponential forgetting factors / data decay
    - weighted ensemble learning


`@script`



---
## You're ready to tackle the exercise on online learning!

```yaml
type: "FinalSlide"
key: "32422b5027"
```

`@script`


