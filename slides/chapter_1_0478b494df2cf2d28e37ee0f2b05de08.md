---
title: Insert title here
key: 0478b494df2cf2d28e37ee0f2b05de08

---
## Dataset Shift and Domain Adaptation

```yaml
type: "TitleSlide"
key: "97d7bf3bf0"
```

`@lower_third`

name: Chris Anagnostopoulos
title: Dr.


`@script`
Welcome back! Sometimes, machine learning models perform less well in production than during development. This can cause much disappointment, and is commonly attributed to overfitting, a topic we covered earlier. There is however another possibility: your production data might differ in subtle ways from your training data, so that the patterns your model correctly picked up become less relevant. Let's see what we can do about that.


---
## What is dataset shift?

```yaml
type: "FullSlide"
key: "f487295fbe"
```

`@part1`
**Temporal data shift**: 
- The presence of the keyword "Microsoft Excel" in a Curriculum Vitae has become less important as a predictor of a good applicant for a data analysis job.
- With the introduction of two-step authentication techniques, multiple password attempts are less frequently involved in cyber attacks.

**Change of domain** or **source**: 

- An OCR (optical character recognition) software might be deployed on wrinkled, faded receipts, whereas it was trained on high quality scanned documents. 
- An app that predicts imminent heart attack was trained only on elderly males.


`@script`
Sometimes, the data generating process evolves over time. For example, if you were building a decision making tool for recruitment of data analysts, skills that used to be relevant in the past might be less so today. Similarly, as defences become more sophisticated, so do hackers' attempts to evade them, causing signatures of known attacks to quickly become obsolete. Time is not the only factor at play, however. Especially in novel products, the process generating training data is almost always slightly different to the production environment. For example, academic or open-source datasets might be used to train an algorithm which is then deployed in a brand-new consumer product.


---
## A real example of dataset shift.

```yaml
type: "TwoRows"
key: "ed43677062"
```

`@part1`
- The `electricity` dataset is popular in the literature on dataset shift. 
- Class: `up` or `down`, 5 features (plus timestamp), 45312 instances. 
- You can find more information [here](https://www.openml.org/d/151). For now, let's import it and sort by date. 
- Next, we will fit the same classifier to older and more recent data, and assess its accuracy against the most recent 500 examples.


`@part2`
```python
import pandas as pd
df = pd.read_csv(
    'https://www.openml.org/data/get_csv/2419/electricity-normalized.arff'
)
df = df.sort_values(by='date').reset_index().drop(['date', 'index'], axis=1)
print(df.head(3))
   day    period  nswprice  nswdemand  vicprice  vicdemand  transfer class
0    2  0.000000  0.056443   0.439155  0.003467   0.422915  0.414912    UP
1    2  0.553191  0.042482   0.499554  0.003467   0.422915  0.414912  DOWN
2    2  0.574468  0.044374   0.491669  0.003467   0.422915  0.414912    UP
```


`@script`
It probably seems obvious that deploying a model on data that are very different from its training set is a bad idea. But let's review some technical detail to understand precisely what is at play here. We will look at a dataset which is popular in this literature, called "electricity". The aim is to forecast electricity price movements on the basis of a number of features. Your class label is "UP" or "DOWN". This trick of turning a forecasting problem into a classification problem is worth keeping in mind, as it allows you to use your standard pipeline in a broader set of problems.


---
## Why is it a problem?

```yaml
type: "TwoRowsWideBottom"
key: "878dd774d9"
```

`@part1`
```python
from sklearn import naive_bayes as nb, metrics
training_data = {'old': df.loc[0:20000], 'new': df.loc[20001:40000]}
live_data = df.loc[40001:]
models = {key: nb.GaussianNB().fit(X=val.drop('class', 1), y=val['class'])
          for key, val in training_data.items()}
predictions = {key: val.predict(live_data.drop('class', 1))
               for key, val in models.items()}
accuracies = {key: metrics.accuracy_score(live_data['class'], val)
              for key, val in predictions.items()}
print({key: '{:f}'.format(val) for key, val in accuracies.items()})
{'new': '0.823574', 'old': '0.787987'}
```


`@part2`
When facing dataset shift, you risk fitting the  parameters of your model to obsolete patterns, leading to poor accuracy, as in the example above. However, dataset shift **does not always** hurt your model, as some types of shift might not affect the decision boundary .


`@part3`
![](https://assets.datacamp.com/production/repositories/3450/datasets/5d5fbecc3b774ab94af69ea48ab73a8aa98f14e0/shift_types_hard_cropped.png) 
A toy example of harmless dataset shift.


`@script`
To illustrate the effects of dataset shift, we split the data in two batches of 20000 examples each, sorted by date, and hold out the last few thousand examples as our "production" data, to assess accuracy. Using the older batch produces lower accuracy against the production data than the more recent batch. The literature suggests that a change in the structure of electricity provision during the period in question in New South Wales, where this dataset is from, caused the relationship between the features and the electricity price to change. In general, you might not be able to identify why your dataset has shifted, but it is always a possibility to keep in mind: the world tends to be a fairly dynamic place! The good news is that dataset shift does not always hurt: consider, for example, the bottom right figure, where a movement of the two classes leaves the decision boundary, and hence the classifier's accuracy, unaffected.


---
## Data splitting revisited

```yaml
type: "TwoColumns"
key: "9d95c3b273"
```

`@part1`
Labelled production data is expensive, so it is important to use it wisely. In particular, should you use it as test data, training data, or both? 

If you are using **flexible models** (say, random forests or deep networks) and a lot of **model selection**, then your pipeline is likely to be robust to shift in the training set, but not in the test set.

If instead you are using simple models (say, logistic regression) and make light use of the test set (say, just for regularisation), then it is important to have a representative training set.

**Model Selection** >  Test Data
**Flexible Models** > Test Data

f your pipeline relies heavily on model selection (i.e., on your test data), then it is sensible to use all of your production data to drive that component

This is appropriate if your pipeline places great weight on model selection or hyperparameter tuning. If instead your pipeline features just one or two models, then


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/ea4451428be1e0011611606a4f42a8a97706e72f/datasplitting.001.jpeg)


`@script`



---
## The bias-variance perspective

```yaml
type: "FullSlide"
key: "365441976c"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3450/datasets/761ced030ebf6c04c25d6e7440b76fc0a6b32a15/material.001.jpeg)


`@script`
It is easy to see why historical data can remain useful even in the presence of dataset shift. Let's consider the optimal parameter values for the production process, theta star prod, and the respective values for the historical process, theta star history. These are some distance away from each other, corresponding to dataset shift.


---
## The bias-variance perspective

```yaml
type: "FullSlide"
key: "e66a515fa2"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3450/datasets/fc27e3c80a37ddac25add65db8d6e5fe0ae191f9/material.002.jpeg)


`@script`
However, we do not have access to optimal parameter values: the best we can do is estimate them from data. A large historical dataset will ensure we land in a small neighborhood of the optimal value, whereas a small production dataset means there will be a lot of variance in that estima


---
## The bias-variance perspective

```yaml
type: "FullSlide"
key: "100a263b43"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3450/datasets/04835d7357807f78ea592638413d006596bd79e9/material.003.jpeg)


`@script`



---
## The bias-variance perspective

```yaml
type: "FullSlide"
key: "7664e8408c"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3450/datasets/431175f60ca0b637fd9c834754716b42208abbc0/material.004.jpeg)


`@script`



---
## The bias-variance perspective

```yaml
type: "FullSlide"
key: "ea0825ee84"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/3450/datasets/dc2ce100e0a635dbe81f00701eeb437d93a06bc0/material.005.jpeg)


`@script`



---
## The Landscape of Solutions

```yaml
type: "TwoColumns"
key: "513c83f7e7"
```

`@part1`
There are several different ways to handle dataset shift:
- pre-training and model initialisation


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/d7acecef3d765a4b738ff4969afff21c2ba23834/surface.png)


`@script`



---
## The Landscape of Solutions

```yaml
type: "TwoColumns"
key: "a5167b39e6"
```

`@part1`
There are several different ways to handle dataset shift:
- pre-training and model initialisation
- transfer learning


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/32f1c1a1439504fe2148b46fc393d9b819df75e0/transfer.001.jpeg)


`@script`



---
## The Landscape of Solutions

```yaml
type: "TwoColumns"
key: "9d2128bd6a"
```

`@part1`
There are several different ways to handle dataset shift:
- pre-training and model initialisation
- transfer learning
- model and/or data averaging
    - exponential forgetting factors
    - weighted ensemble learning


`@part2`
![](https://assets.datacamp.com/production/repositories/3450/datasets/09ffbc511484b4ff19515c169614c62654cb3289/decay.png)
A data decay function.
![](https://assets.datacamp.com/production/repositories/3450/datasets/4e19da6c043668d0c7d2ae6674b313d3be87b18b/weights.png)
The weights of an ensemble learner.


`@script`



---
## You're ready to tackle the exercise on online learning!

```yaml
type: "FinalSlide"
key: "32422b5027"
```

`@script`


